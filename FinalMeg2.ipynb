{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name of Professor  \\\n",
      "0               Anima Anandkumar   \n",
      "1              Prabha R. Acharya   \n",
      "2                Piyush S. Agram   \n",
      "3         Rayomand (Rayo) Bhadha   \n",
      "4               Aparna Bhaskaran   \n",
      "5                  Rana Adhikari   \n",
      "6                  Sunil Golwala   \n",
      "7              Mansi M. Kasliwal   \n",
      "8   Shrinivas R. (Shri) Kulkarni   \n",
      "9           Dinakar Ramakrishnan   \n",
      "10                   Vikram Ravi   \n",
      "\n",
      "                                          Description  \n",
      "0   Bren Professor of Computing and Mathematical S...  \n",
      "1                          Software Systems Developer  \n",
      "2                    Visiting Associate in Geophysics  \n",
      "3                   Seismic Network Technical Manager  \n",
      "4                 Database Analyst/Software Developer  \n",
      "5                                Professor of Physics  \n",
      "6   Professor of Physics; Director, Caltech Submil...  \n",
      "7                    Assistant Professor of Astronomy  \n",
      "8   George Ellery Hale Professor of Astronomy and ...  \n",
      "9      Taussky-Todd-Lonergan Professor of Mathematics  \n",
      "10                   Assistant Professor of Astronomy  \n"
     ]
    }
   ],
   "source": [
    "#Shabeg Singh Gill\n",
    "#IIITD\n",
    "\n",
    "import pandas as pd \n",
    "import requests \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as b\n",
    "from urllib.request import Request, urlopen\n",
    "from collections import OrderedDict\n",
    "\n",
    "ls=[] #list for links \n",
    "hr=[]\n",
    "\n",
    "#getting all links first \n",
    "for x in range(1,2):\n",
    "    mainurl= \"https://www.caltech.edu\"\n",
    "    req= requests.get(mainurl)\n",
    "    soup= b(req.content,'html.parser') \n",
    "    links= soup.find_all('a') #for links \n",
    "    #for hrefs only \n",
    "#extracting hrefs and adding to links ki list \n",
    "for i in links:\n",
    "    mainurl= \"https://www.caltech.edu\"\n",
    "    if i.get('href') is not None:\n",
    "        if 'instagram' not in i.get('href') and 'youtube' not in i.get('href') :\n",
    "            j= i.get('href')\n",
    "            hr.append(j)\n",
    "            ls.append(mainurl+ str(j))\n",
    "\n",
    "aa=0 #for duplication check of dept names \n",
    "c=0 #for duplication check of dept links \n",
    "#for reaching faculty webpage\n",
    "deptns=[] #list for dept names \n",
    "deptls=[] #lsit for dept links \n",
    "\n",
    "for i in soup.find_all('a'): \n",
    "    mainurl= \"https://www.caltech.edu\"\n",
    "    if i.get('href') is not None and i.get('href')== \"/research/faculty-listing\" :\n",
    "        x=1\n",
    "        j= i.get('href')\n",
    "        cururl = mainurl +j \n",
    "        req2= requests.get(cururl)\n",
    "        #req2= requests.get(cururl)\n",
    "        soup2= b(req2.content, 'html.parser')\n",
    "        #print(soup)\n",
    "        \n",
    "        deptnames =soup2.find('section', {'class': 'block-AirspaceRichTextBlock'}).find('div', {'class': 'airspace-rich-text'}).find_all('b')\n",
    "        deptlinks= soup2.find('section', {'class': 'block-AirspaceRichTextBlock'}).find('div', {'class': 'airspace-rich-text'}).findAll('h4')\n",
    "        \n",
    "        for i in deptnames :\n",
    "            i = i .text \n",
    "            if i=='Biology & Biological Engineering Faculty': \n",
    "               \n",
    "                aa=aa+1\n",
    "            if aa==2:\n",
    "                break\n",
    "                \n",
    "            deptns.append(i)\n",
    "            \n",
    "                \n",
    "        \n",
    "        for i in deptlinks:\n",
    "            j=i.find('a').get('href')\n",
    "            \n",
    "            if j==\"http://www.bbe.caltech.edu/people?cat_one=Faculty&cat_two=all\":\n",
    "                c=c+1\n",
    "                if c==1:\n",
    "                    deptls.append(j)\n",
    "                else :\n",
    "                    break\n",
    "            \n",
    "            else :\n",
    "                deptls.append(j)\n",
    "                \n",
    "#now we have deptls for dept links \n",
    "#now we have deptns for dept names\n",
    "\n",
    "#students- Surjyendu Bhattacharjee, \n",
    "\n",
    "#indian faculty \n",
    "ind=[\"Anima Anandkumar\", \"Gargi Kulkarni\", \"Dinesh S. Rao\", \"Prabha R. Acharya\", \"Piyush S. Agram\", \"Aparna Bhaskaran\", \n",
    "    \"Rayomand (Rayo) Bhadha\",\"Yayaati Chachan\", \"Yamini Jangir\", \"Hemani Kalucha\", \"Sriharsha Kandala\", \n",
    "    \"Shrinivas R. (Shri) Kulkarni\", \"Ranjani Murali\", \"Mudit Murarka\", \"Akshay Sridhar\", \"Rana Adhikari\", \"Sunil Golwala\",\"Mansi M. Kasliwal\", \"Shrinivas R. (Shri) Kulkarni\", \"Dinakar Ramakrishnan\", \"Vikram Ravi\", \"Animashree (Anima) Anandkumar\", \"Kaushik Bhattacharya\", \"Venkat Chandrasekaran\", \"Urmila Mahadev\", \"Guruswami (Ravi) Ravichandran\", \"P. P. Vaidyanathan\"]\n",
    "\n",
    "deptls.remove('http://eas.caltech.edu/people')\n",
    "deptls.remove('http://www.hss.caltech.edu/people?cat_one=Professorial%20Faculty&cat_two=all')\n",
    "deptls.remove('http://pma.divisions.caltech.edu/people?cat_one=Professorial%20Faculty&cat_two=all')\n",
    "facnames=[]\n",
    "namesls=[]\n",
    "indnames=[]\n",
    "dicts={}\n",
    "descs=[]\n",
    "for i in deptls :\n",
    "    cururl= i +'&p=' #current dept url for indian faculty filtering \n",
    "    #req= requests.get(cururl)\n",
    "    #soup= b (req.content, 'html.parser')\n",
    "    for j in range(1,10): #for page number iteration \n",
    "        cururl= cururl+str(j) \n",
    "        req= requests.get(cururl)\n",
    "        soup= b (req.content, 'html.parser')\n",
    "        #names= soup.find_all('div', {'class': 'person-teaser__title'})\n",
    "        names= soup.find_all('div', {'class': 'person-teaser__info'})\n",
    "        #descs= soup.find_all('div', {'class': 'person-teaser__job-title'})\n",
    "        for k in names:\n",
    "            #name below \n",
    "            title= k.find('a').text\n",
    "            desc= k.find('div', {'class':'person-teaser__job-title'}).text\n",
    "            namesls.append(title)\n",
    "            dicts[title.strip()]=desc.strip()\n",
    "            \n",
    "\n",
    "\n",
    "#now I'm done with the first 3 web pages , moving onto the next 3 now\n",
    "#code of first 3 is same in terms of tags, code of last 3 except last  websites is same in terms of tags \n",
    "\n",
    "deptls2=[]\n",
    "deptls2.append('http://www.hss.caltech.edu/people?cat_one=Professorial%20Faculty&cat_two=all')\n",
    "deptls2.append('http://pma.divisions.caltech.edu/people?cat_one=Professorial%20Faculty&cat_two=all')\n",
    "\n",
    "for i in deptls2:\n",
    "    cururl= i +'&p=' #current dept url for indian faculty filtering \n",
    "    for j in range(1,10): #for page number iteration \n",
    "        cururl= cururl+str(j) \n",
    "        req= requests.get(cururl)\n",
    "        soup= b (req.content, 'html.parser')\n",
    "        names= soup.find_all('div', {'class':'person-listing__person-row'})\n",
    "        for k in names:\n",
    "            title= k.find('span', {'class':'sr-only'}).text \n",
    "            desc= k.find('div', {'class':'person-listing__summary__faculty-title'}).text\n",
    "            namesls.append(title)\n",
    "            dicts[title.strip()]=desc.strip()\n",
    "            \n",
    "\n",
    "\n",
    "#for final webpage now \n",
    "finpage= 'http://www.hss.caltech.edu/people?cat_one=Professorial%20Faculty&cat_two=all'\n",
    "finpage= finpage + '&p='\n",
    "for j in range(1, 10):\n",
    "    cururl= cururl+str(j)\n",
    "    req= requests.get(cururl)\n",
    "    soup=b(req.content, 'html.parser')\n",
    "    names= soup.find_all('div', {'class':'post'})\n",
    "    for k in names:\n",
    "        title= k.find('strong', {'class':'name'}).find('a').text \n",
    "        desc= k.find('p')\n",
    "        namesls.append(title)\n",
    "        dicts[title.strip()]=desc.strip()\n",
    "        \n",
    "        \n",
    "check=0 \n",
    "for j in namesls:\n",
    "    #if '\\n' in j :\n",
    "    j=j.strip()\n",
    "    #j.remove('\\n')\n",
    "    #print(j)\n",
    "    if j in ind:\n",
    "        check=1\n",
    "        indnames.append(j)\n",
    "        \n",
    "for i in dicts:\n",
    "    check=1\n",
    "    #checking if the dict key is part of indian nnames list \n",
    "    if i in indnames:\n",
    "        descs.append(dicts[i]) #getting description by accessing value \n",
    "\n",
    "#getting names \n",
    "#for k in indnames:\n",
    "    #print(k)\n",
    "    \n",
    "#getting descriptions \n",
    "#for i in descs :\n",
    "    #print(i)  \n",
    "    \n",
    "#print(dicts)\n",
    " \n",
    "#removing duplicates from indian faculty list     \n",
    "rest = list(OrderedDict.fromkeys(indnames))\n",
    "\n",
    "\n",
    "#csv file-1 for indian faculty only\n",
    "b= {'Name of Professor':rest, 'Description': descs}\n",
    "df1=  pd.DataFrame.from_dict(b, orient='index') \n",
    "df1=df1.transpose() \n",
    "print(df1)\n",
    "df1.to_csv('IndianFac.csv') #csv file-1         \n",
    "            \n",
    "    \n",
    "#print(rest)     \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
